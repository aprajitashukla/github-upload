@article{Yu2017,
abstract = {We motivate and describe a new freely available human-human dialogue data set for interactive learning of visually grounded word meanings through osten-sive definition by a tutor to a learner. The data has been collected using a novel, character-by-character variant of the DiET chat tool (Healey et al., 2003; Mills and Healey, submitted) with a novel task, where a Learner needs to learn invented visual attribute words (such as " burchak " for square) from a tutor. As such, the text-based interactions closely resemble face-to-face conversation and thus contain many of the linguistic phenomena encoun-tered in natural, spontaneous dialogue. These include self-and other-correction, mid-sentence continuations, interruptions, overlaps, fillers, and hedges. We also present a generic n-gram framework for building user (i.e. tutor) simulations from this type of incremental data, which is freely available to researchers. We show that the simulations produce outputs that are similar to the original data (e.g. 78{\%} turn match similarity). Finally, we train and evaluate a Reinforcement Learning di-alogue control agent for learning visually grounded word meanings, trained from the BURCHAK corpus. The learned policy shows comparable performance to a rule-based system built previously.},
author = {Yu, Yanchao and Eshghi, Arash and Mills, Gregory and Lemon, Oliver},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yu, Mills - 2017 - The BURCHAK corpus a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings.pdf:pdf},
keywords = {corpora,corpus,grounding,language acquisition,symbol grounding},
mendeley-tags = {corpora,grounding,language acquisition,symbol grounding},
pages = {1--10},
title = {{The BURCHAK corpus: a Challenge Data Set for Interactive Learning of Visually Grounded Word Meanings}},
year = {2017}
}
@inproceedings{houghschlangenHRI2017,
author = {Hough, Julian and Schlangen, David},
booktitle = {Proceedings of the 2017 Conference on Human-Robot Interaction (HRI2017)},
file = {:home/ckennington/Desktop/p274-hough.pdf:pdf},
title = {{It's Not What You Do, It's How You Do It: Grounding Uncertainty for a Simple Robot}},
year = {2017}
}
@inproceedings{Dobnik2017,
author = {Dobnik, Simon and Graaf, Erik Wouter De},
booktitle = {Proceedings of the 21st Nordic},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dobnik, Graaf - 2017 - KILLE a Framework for Situated Agents for Learning Language Through Interaction.pdf:pdf},
keywords = {grounding,language acquisition,symbol grounding},
mendeley-tags = {grounding,language acquisition,symbol grounding},
number = {May},
pages = {162--171},
title = {{KILLE : a Framework for Situated Agents for Learning Language Through Interaction}},
year = {2017}
}
@article{Lewis2013,
abstract = {We introduce a new approach to semantics which combines the benefits of distributional and formal logical semantics. Distributional models have been successful in modelling the meanings of content words, but logical semantics is necessary to adequately represent many function words. We follow formal semantics in mapping language to logical representations, but differ in that the relational constants used are induced by offline distributional clustering at the level of predicate- argument structure. Our clustering algorithm is highly scalable, allowing us to run on corpora the size of Gigaword. Different senses of a word are disambiguated based on their induced types. We outperform a variety of existing approaches on a wide-coverage question answering task, and demonstrate the ability to make complex multi-sentence inferences involving quantifiers on the FraCaS suite.},
author = {Lewis, Mike and Steedman, Mark},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lewis, Steedman - 2013 - Combined Distributional and Logical Semantics(2).pdf:pdf},
issn = {2307-387X},
journal = {Transactions of the ACL},
keywords = {nlu,semantics},
mendeley-tags = {nlu,semantics},
pages = {179--192},
title = {{Combined Distributional and Logical Semantics}},
url = {http://www.mendeley.com/research/combined-distributional-logical-semantics/},
volume = {1},
year = {2013}
}
@article{Devault2011,
abstract = {We present techniques for the incremental interpretation and prediction of utterance meaning in dialogue systems. These techniques open possibilities for systems to initiate responsive overlap be-haviors during user speech, such as interrupting, acknowledging, or completing a user's utterance while it is still in progress. In an implemented system, we show that relatively high accuracy can be achieved in understanding of spontaneous utterances before utterances are completed. Further, we present a method for determining when a system has reached a point of maximal understanding of an ongoing user utterance, and show that this determination can be made with high precision. Finally, we discuss a prototype implementation that shows how systems can use these abilities to strategically initiate system completions of user utterances. More broadly, this framework facili-tates the implementation of a range of overlap behaviors that are common in human dialogue, but have been largely absent in dialogue systems.},
author = {Devault, David and Sagae, Kenji and Traum, David},
doi = {10.5087/dad.2011.107},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Devault, Sagae, Traum - 2011 - Incremental Interpretation and Prediction of Utterance Meaning for Interactive Dialogue(2).pdf:pdf},
issn = {2152-9620},
journal = {Dialogue and Discourse},
keywords = {dialogue management,dm,incremental,nlu},
mendeley-tags = {dialogue management,dm,incremental,nlu},
number = {1},
pages = {143--170},
title = {{Incremental Interpretation and Prediction of Utterance Meaning for Interactive Dialogue}},
url = {http://www.elanguage.net/journals/dad/article/view/456/1458},
volume = {2},
year = {2011}
}
@article{Hollich2000,
author = {Hollich, George and Tucker, Michael and Golkinoff, Roberta},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hollich, Tucker, Golkinoff - 2000 - The Change is Afoot Emergentist Thinking in Language Acquisition(2).pdf:pdf},
keywords = {feedback,language acquisition},
mendeley-tags = {feedback,language acquisition},
title = {{The Change is Afoot: Emergentist Thinking in Language Acquisition}},
year = {2000}
}
@inproceedings{louwerse2007multimodal,
author = {Hadelich, Kerstin and Branigan, Holly P and Pickering, Martin J and Crocker, Matthew W},
booktitle = {Proceedings of the 8th Workshop on the Semantics and Pragmatics of Dialogue, Catalog'04},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Hadelich et al. - 2004 - Alignment in dialogue Effects of visual versus verbal-feedback(2).pdf:pdf},
keywords = {dissertation,psycholinguistics},
mendeley-tags = {dissertation,psycholinguistics},
pages = {35--40},
title = {{Alignment in dialogue: Effects of visual versus verbal-feedback}},
year = {2004}
}
@phdthesis{KenningtonDissertation2016,
abstract = {The primary concern of this thesis is to model the resolution of spoken referring expressions made in order to identify objects; in particular, everyday objects that can be perceived visually and distinctly from other objects. The practical goal of such a model is for it to be implemented as a component for use in a live, interactive, autonomous spoken dialogue system. The requirement of interaction imposes an added complication; one that has been ignored in previous models and approaches to automatic reference resolution: the model must attempt to resolve the reference incrementally as it unfolds–not wait until the end of the referring expression to begin the resolution process. Beyond components in dialogue systems, reference has been a major player in the philosophy of meaning for longer than a century. For example, Gottlob Frege (1892) has distinguished between Sinn (sense) and Bedeutung (reference), discussed how they are related and how they relate to the meaning of words and expressions. It has furthermore been argued (e.g., Dahlgren (1976)) that reference to entities in the actual world is not just a fundamental notion of semantic theory, but the fundamental notion; for an individual acquiring a language, understanding the meaning of many words and concepts is done via the task of reference, beginning in early childhood. In this thesis, we pursue an account of word meaning that is based on perception of objects; for example, the meaning of the word red is based on visual features that are selected as distinguishing red objects from non-red ones. This thesis proposes two statistical models of incremental reference resolution. Given ex- amples of referring expressions and visual aspects of the objects to which those expressions referred, both model components learn a functional mapping between the words of the refer- ring expressions and the visual aspects. A generative model, the simple incremental update model, presented in Chapter 5, uses a mediating variable to learn the mapping, whereas a dis- criminative model, the words-as-classifiers model, presented in Chapter 6, learns the mapping directly and improves over the generative model. Both models have been evaluated in various reference resolution tasks to objects in virtual scenes as well as real, tangible objects. This thesis shows that both models work robustly and are able to resolve referring expressions made in reference to visually present objects despite realistic, noisy conditions of speech and object recognition. A theoretical and practical comparison is also provided. Special emphasis is given to the discriminative model in this thesis because of its simplicity and ability to represent word meanings. It is in the learning and application of this model that gives credence to the above claim that reference is the fundamental notion for semantic theory and that meanings of (visual) words is done through experiencing referring expressions made to objects that are visually perceivable.},
author = {Kennington, Casey},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kennington - 2016 - Incrementally resolving references in order to identify visually present objects in a situated dialogue setting(2).pdf:pdf},
publisher = {Universit{\"{a}}t Bielefeld},
school = {Universit{\"{a}}t Bielefeld},
title = {{Incrementally resolving references in order to identify visually present objects in a situated dialogue setting}},
year = {2016}
}
@inproceedings{Dobnika,
abstract = {We present KILLE, a framework for situ-ated agents for learning language through interaction with its environment (percep-tion) and with a human tutor (dialogue). We provide proof-of-concept evaluations of the usability of the system in two do-mains: learning of object categories and learning of spatial relations.},
author = {Dobnik, Simon and Graaf, Erik Wouter De},
booktitle = {Proceedings of the 21st Nordic},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Dobnik, Graaf - 2017 - KILLE a Framework for Situated Agents for Learning Language Through Interaction.pdf:pdf},
number = {May},
pages = {162--171},
publisher = {Link{\"{o}}ping University Electronic Press},
title = {{KILLE : a Framework for Situated Agents for Learning Language Through Interaction}},
url = {http://www.ep.liu.se/ecp/131/019/ecp17131019.pdf},
year = {2017}
}
@inproceedings{Fernandez2012,
author = {Fern{\'{a}}ndez, Raquel},
booktitle = {Proceedings of the PRE-CogSci 2013 Workshop on the Production of Referring Expressions},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Fern{\'{a}}ndez - 2013 - Rethinking Overspecification in Terms of Incremental Processing(2).pdf:pdf},
keywords = {comprehension,incre-,mentality,nlu,overspecification,production,referring expressions},
mendeley-tags = {nlu},
title = {{Rethinking Overspecification in Terms of Incremental Processing}},
year = {2013}
}
@article{artzi2013uwspf,
abstract = {The context in which language is used pro- vides a strong signal for learning to recover its meaning. In this paper, we show it can be used within a grounded CCGsemantic parsing approach that learns a joint model of meaning and context for interpreting and executing natural language instructions, using various types of weak supervision. The joint nature provides crucial benefits by allowing situated cues, such as the set of visible objects, to di- rectly influence learning. It also enables algo- rithms that learn while executing instructions, for example by trying to replicate human ac- tions. Experiments on a benchmark naviga- tional dataset demonstrate strong performance under differing forms of supervision, includ- ing correctly executing 60{\%} more instruction sets relative to the previous state of the art.},
author = {Artzi, Yoav and Zettlemoyer, Luke},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Artzi, Zettlemoyer - 2013 - Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions(2).pdf:pdf},
issn = {2307-387X},
journal = {Transactions of ACL},
keywords = {nlu},
mendeley-tags = {nlu},
pages = {49--62},
title = {{Weakly Supervised Learning of Semantic Parsers for Mapping Instructions to Actions}},
volume = {1},
year = {2013}
}
@inproceedings{Kelleher2006,
abstract = {This paper presents an approach to incrementally generating locative expressions. It addresses the is- sue of combinatorial explosion inherent in the con- struction of relational context models by: (a) con- textually defining the set of objects in the context that may function as a landmark, and (b) sequenc- ing the order in which spatial relations are consid- ered using a cognitively motivated hierarchy of relations, and visual and discourse salience.},
author = {Kelleher, John D and Kruijff, G-J Geert-Jan},
booktitle = {Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics (COLING-ACL'06)},
doi = {10.3115/1220175.1220306},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Kelleher, Kruijff - 2006 - Incremental generation of spatial referring expressions in situated dialog(2).pdf:pdf},
isbn = {1932432655},
keywords = {generation,nlg},
mendeley-tags = {generation,nlg},
number = {July},
pages = {1041--1048},
title = {{Incremental generation of spatial referring expressions in situated dialog}},
url = {http://dl.acm.org/citation.cfm?id=1220306},
year = {2006}
}
@inproceedings{bussetal:collab,
abstract = {When dialogue systems, through the use of incremental processing, are not bounded anymore by strict, non-overlapping turn-taking, a whole range of additional interactional devices becomes available. We explore the use of one such device, trial intonation. We elaborate our approach to dialogue management in incremental systems, based on the Information-State-Update approach, and discuss an implementation in a microdomain that lends itself to the use of immediate feedback, trial intonations and expansions. In an overhearer evaluation, the incremental system was judged as significantly more human-like and reactive than a non-incremental version.},
address = {Tokyo, Japan},
author = {Okko, Bu{\ss} and Baumann, Timo and Schlangen, David},
booktitle = {Proceedings of SIGdial},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Okko, Baumann, Schlangen - 2010 - Collaborating on Utterances with a Spoken Dialogue System Using an ISU-based Approach to Incrementa(2).pdf:pdf},
isbn = {9781932432855},
keywords = {dialogue-management,dm state-tracking},
mendeley-tags = {dialogue-management,dm state-tracking},
month = {sep},
pages = {233--236},
title = {{Collaborating on Utterances with a Spoken Dialogue System Using an ISU-based Approach to Incremental Dialogue Management}},
url = {http://portal.acm.org/citation.cfm?id=1944547},
year = {2010}
}
@article{Lucking2014,
author = {L{\"{u}}cking, Andy and Mehler, Alexander},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/L{\"{u}}cking, Mehler - 2014 - On Three Notions of Grounding of Artificial Dialog Companions.pdf:pdf},
journal = {Science, Technology {\&} Innovation Studies},
keywords = {interaction},
mendeley-tags = {interaction},
number = {1},
title = {{On Three Notions of Grounding of Artificial Dialog Companions}},
volume = {10},
year = {2014}
}
@article{Stolcke2000,
abstract = {We describe a statistical approach for modeling dialogue acts in conversational speech, i.e., speech-act-like units such as STATEMENT, Question, BACKCHANNEL, Agreement, Disagreement, and Apology. Our model detects and predicts dialogue acts based on lexical, collocational, and prosodic cues, as well as on the discourse coherence of the dialogue act sequence. The dialogue model is based on treating the discourse structure of a conversation as a hidden Markov model and the individual dialogue acts as observations emanating from the model states. Constraints on the likely sequence of dialogue acts are modeled via a dialogue act n-gram. The statistical dialogue grammar is combined with word n-grams, decision trees, and neural networks modeling the idiosyncratic lexical and prosodic manifestations of each dialogue act. We develop a probabilistic integration of speech recognition with dialogue modeling, to improve both speech recognition and dialogue act classification accuracy. Models are trained and evaluated using a large hand-labeled database of 1,155 conversations from the Switchboard corpus of spontaneous human-to-human telephone speech. We achieved good dialogue act labeling accuracy (65{\%} based on errorful, automatically recognized words and prosody, and 71{\%} based on word transcripts, compared to a chance baseline accuracy of 35{\%} and human accuracy of 84{\%}) and a small reduction in word recognition error.},
archivePrefix = {arXiv},
arxivId = {cs/0006023},
author = {Stolcke, A. and Ries, K. and Coccaro, N. and Shriberg, E. and Bates, R. and Jurafsky, D. and Taylor, P. and Martin, R. and Ess-Dykema, C.V. and Meteer, M.},
doi = {10.1162/089120100561737},
eprint = {0006023},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stolcke et al. - 2000 - Dialogue act modeling for automatic tagging and recognition of conversational speech(2).pdf:pdf},
isbn = {089120100561737},
issn = {0891-2017},
journal = {Computational linguistics},
keywords = {dialogue,dialogue systems},
mendeley-tags = {dialogue,dialogue systems},
month = {sep},
number = {3},
pages = {339--373},
primaryClass = {cs},
publisher = {MIT Press},
title = {{Dialogue act modeling for automatic tagging and recognition of conversational speech}},
url = {http://www.mitpressjournals.org/doi/pdfplus/10.1162/089120100561737},
volume = {26},
year = {2000}
}
@inproceedings{Chai2014,
abstract = {In situated human-robot dialogue, although humans and robots are co-present in a shared environment, they have significantly mismatched capabilities in perceiving the shared environment. Their representations of the shared world are misaligned. In order for humans and robots to communicate with each other successfully using language, it is important for them to mediate such differences and to establish common ground. To address this issue, this paper describes a dialogue system that aims to mediate a shared perceptual basis during human-robot dialogue. In particular, we present an empirical study that examines the role of the robot's collaborative effort and the performance of natural language processing modules in dialogue grounding. Our empirical results indicate that in situated human-robot dialogue, a low collaborative effort from the robot may lead its human partner to believe a common ground is established. However, such beliefs may not reflect true mutual understanding. To support truly grounded dialogues, the robot should make an extra effort by making its partner aware of its internal representation of the shared world.},
address = {Bielefeld, Germany},
author = {Chai, Joyce Y and She, Lanbo and Fang, Rui and Ottarson, Spencer and Littley, Cody and Liu, Changsong and Hanson, Kenneth},
booktitle = {Proceedings of the 2014 ACM/IEEE international conference on Human-robot interaction},
doi = {10.1145/2559636.2559677},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Chai et al. - 2014 - Collaborative effort towards common ground in situated human-robot dialogue(2).pdf:pdf},
isbn = {9781450326582},
issn = {21672148},
keywords = {collaboration,common ground,human-robot,nlu,robotics},
mendeley-tags = {nlu,robotics},
pages = {33--40},
title = {{Collaborative effort towards common ground in situated human-robot dialogue}},
year = {2014}
}
@inproceedings{khouzaimi-laroche-lefevre:2014:W14-43,
address = {Philadelphia, PA, U.S.A.},
author = {Khouzaimi, Hatim and Laroche, Romain and Lefevre, Fabrice},
booktitle = {Proceedings of the 15th Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Khouzaimi, Laroche, Lefevre - 2014 - An easy method to make dialogue systems incremental(2).pdf:pdf},
keywords = {dialogue,dialogue management,dialogue systems,dm,incremental},
mendeley-tags = {dialogue,dialogue management,dialogue systems,dm,incremental},
number = {June},
pages = {98--107},
publisher = {Association for Computational Linguistics},
title = {{An easy method to make dialogue systems incremental}},
url = {http://www.aclweb.org/anthology/W14-4314},
year = {2014}
}
@inproceedings{Hana,
abstract = {Grounded semantics is typically learnt from utterance-level meaning representa-tions (e.g., successful database retrievals, denoted objects in images, moves in a game). We explore learning word and ut-terance meanings by continuous observa-tion of the actions of an instruction fol-lower (IF). While an instruction giver (IG) provided a verbal description of a config-uration of objects, IF recreated it using a GUI. Aligning these GUI actions to sub-utterance chunks allows a simple maxi-mum entropy model to associate them as chunk meaning better than just providing it with the utterance-final configuration. This shows that semantics useful for in-cremental (word-by-word) application, as required in natural dialogue, might also be better acquired from incremental settings.},
author = {Han, Ting and Schlangen, David},
booktitle = {Proceedings of EACL: Volume 2, Short Papers},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Han, Schlangen - Unknown - Grounding Language by Continuous Observation of Instruction Following.pdf:pdf},
keywords = {grounding,interaction,symbol grounding},
mendeley-tags = {grounding,interaction,symbol grounding},
pages = {491--496},
publisher = {Association for Computational Linguistics},
title = {{Grounding Language by Continuous Observation of Instruction Following}},
url = {http://aclweb.org/anthology/E/E17/E17-2079.pdf},
volume = {2},
year = {2017}
}
@article{Yang2011,
abstract = {In this article we focus on human-human multi-tasking dialogues, in which pairs of conversants, using speech, work on an ongoing task while occasionally completing real-time tasks. The ongoing task is a poker game in which conversants need to assemble a poker hand, and the real-time task is a picture game in which conversants need to find out whether they have a certain picture on their displays. We employ empirical corpus studies and machine learning experiments to understand the mechanisms that people use in managing these complex interactions. First, we examine task interruptions: switching from the ongoing task to a real-time task. We find that generally conversants tend to interrupt at a less disruptive context in the ongoing task when possible. We also find that the discourse markers oh and wait occur in initiating a task interruption twice as often as in the conversation of the ongoing task. Pitch is also found to be statistically correlated with task interruptions; in fact, the more disruptive the task interruption, the higher the pitch. Second, we examine task resumptions: returning to the ongoing task after completing an interrupting real-time task. We find that conversants might simply resume the conversation where they left off, but sometimes they repeat the last utterance or summarize the critical information that was exchanged before the interruption. Third, we apply machine learning to determine how well task interruptions can be recognized automatically and to investigate the usefulness of the cues that we find in the corpus studies. We find that discourse context, pitch, and the discourse markers oh and wait are important features to reliably recognize task interruptions; and with non-lexical features one can improve the performance of recognizing task interruptions with more than a 50{\%} relative error reduction over a baseline. Finally, we discuss the implication of our findings for building a speech interface that supports multi-tasking dialogue. [ABSTRACT FROM AUTHOR]},
author = {Yang, Fan and Heeman, Peter a. and Kun, Andrew L.},
doi = {10.1162/coli_a_00036},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Yang, Heeman, Kun - 2011 - An Investigation of Interruptions and Resumptions in Multi-Tasking Dialogues(2).pdf:pdf},
isbn = {10.1162/coli{\_}a{\_}00036},
issn = {0891-2017},
journal = {Computational Linguistics},
keywords = {interaction},
mendeley-tags = {interaction},
number = {1},
pages = {75--104},
title = {{An Investigation of Interruptions and Resumptions in Multi-Tasking Dialogues}},
volume = {37},
year = {2011}
}
@article{Zettlemoyer2009,
abstract = {We consider the problem of learning context-dependent mappings from sentences to logical form. The training examples are sequences of sentences annotated with lambda-calculus meaning representations. We develop an algorithm that maintains explicit, lambda-calculus representations of salient discourse entities and uses a context-dependent analysis pipeline to recover logical forms. The method uses a hidden-variable variant of the perception algorithm to learn a linear model used to select the best analysis. Experiments on context-dependent utterances from the ATIS corpus show that the method recovers fully correct logical forms with 83.7{\%} accuracy.},
address = {Morristown, NJ, USA},
author = {Zettlemoyer, Luke S. and Collins, Michael},
doi = {10.3115/1690219.1690283},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zettlemoyer, Collins - 2009 - Learning context-dependent mappings from sentences to logical form(2).pdf:pdf},
isbn = {9781932432466},
journal = {Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2 - ACL-IJCNLP '09},
keywords = {nlu,semantics},
mendeley-tags = {nlu,semantics},
number = {August},
pages = {976},
publisher = {Association for Computational Linguistics},
title = {{Learning context-dependent mappings from sentences to logical form}},
url = {http://portal.acm.org/citation.cfm?doid=1690219.1690283},
volume = {2},
year = {2009}
}
@article{Bohemia2015,
author = {Bohemia, West},
doi = {10.13140/RG.2.1.4790.5129},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Bohemia - 2015 - Distributional Semantics in Language Modeling.pdf:pdf},
number = {MAY},
pages = {95--101},
title = {{Distributional Semantics in Language Modeling}},
year = {2015}
}
@article{Huettig2015,
abstract = {ABSTRACTSome recent theoretical accounts in the cognitive sciences suggest that prediction is necessary to understand language. Here we evaluate this proposal. We consider arguments that prediction provides a unified theoretical principle of the human mind and that it pervades cortical function. We discuss whether evidence of human abilities to detect statistical regularities is necessarily evidence for predictive processing and evaluate suggestions that prediction is necessary for language learning. We point out that not all language users appear to predict language and that suboptimal input makes prediction often very challenging. Prediction, moreover, is strongly context-dependent and impeded by resource limitations. We also argue that it may be problematic that most experimental evidence for predictive language processing comes from “prediction-encouraging” experimental set-ups. We conclude that languages can be learned and understood in the absence of prediction. Claims that all language processing i...},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Huettig, Falk and Mani, Nivedita},
doi = {10.1080/23273798.2015.1072223},
eprint = {arXiv:1011.1669v3},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Huettig, Mani - 2015 - Language, Cognition and Neuroscience Is prediction necessary to understand language Probably not.pdf:pdf},
isbn = {2327-3798$\backslash$r2327-3801},
issn = {23273801},
journal = {Language, Cognition and Neuroscience},
keywords = {Cognition,Language processing,Learning,Prediction,Predictive coding},
number = {1},
pages = {19--31},
pmid = {9933168},
title = {{Is prediction necessary to understand language? Probably not}},
url = {http://www.tandfonline.com/action/journalInformation?journalCode=plcp21},
volume = {31},
year = {2016}
}
@article{Stoyanchev2012,
author = {Stoyanchev, Svetlana and Stent, Amanda J},
doi = {0.5087/dad.2012.101},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Stoyanchev, Stent - 2012 - Concept Type Prediction and Responsive Adaptation in a Dialogue System(2).pdf:pdf},
journal = {Dialogue and Discourse},
keywords = {dialog structure,error handling,nlu,speech recognition},
mendeley-tags = {nlu},
number = {1},
pages = {1--31},
title = {{Concept Type Prediction and Responsive Adaptation in a Dialogue System}},
volume = {3},
year = {2012}
}
@inproceedings{liu-fang-chai:2012:SIGDIAL2012,
address = {Seoul, South Korea},
author = {Lui, Chansong and Fang, Rui and Chai, Joyce Yue},
booktitle = {Proceedings of the 13th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Lui, Fang, Chai - 2012 - Towards Mediating Shared Perceptual Basis in Situated Dialogue(2).pdf:pdf},
month = {jul},
number = {July},
pages = {140--149},
publisher = {Association for Computational Linguistics},
title = {{Towards Mediating Shared Perceptual Basis in Situated Dialogue}},
url = {http://aclweb.org/anthology-new/W/W12/W12-1621},
year = {2012}
}
@inproceedings{ishizaki1998exploring,
author = {Ishizaki, Masato and Kato, Tsuneaki},
booktitle = {Proceedings of the 36th annual meeting on Association for Computational Linguistics -},
doi = {10.3115/980845.980942},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Ishizaki, Kato - 1998 - Exploring the characteristics of multi-party dialogues(2).pdf:pdf},
keywords = {interaction},
mendeley-tags = {interaction},
organization = {Association for Computational Linguistics},
pages = {583},
title = {{Exploring the characteristics of multi-party dialogues}},
url = {http://portal.acm.org/citation.cfm?doid=980845.980942},
volume = {1},
year = {1998}
}
@inproceedings{zhao-EtAl:2016:SIGDIAL,
address = {Los Angeles},
author = {Zhao, Ran and Sinha, Tanmay and Black, Alan and Cassell, Justine},
booktitle = {Proceedings of the 17th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Zhao et al. - 2016 - Automatic Recognition of Conversational Strategies in the Service of a Socially-Aware Dialog System.pdf:pdf},
keywords = {disclosure,medical},
mendeley-tags = {disclosure,medical},
month = {sep},
pages = {381--392},
publisher = {Association for Computational Linguistics},
title = {{Automatic Recognition of Conversational Strategies in the Service of a Socially-Aware Dialog System}},
url = {http://www.aclweb.org/anthology/W16-3647},
year = {2016}
}
@inproceedings{DeVault2009,
abstract = {We investigate novel approaches to responsive overlap behaviors in dialogue systems, opening possibilities for systems to interrupt, acknowledge or complete a user's utterance while it is still in progress. Our specific contributions are a method for determining when a system has reached a point of maximal understanding of an ongoing user utterance, and a prototype implementation that shows how systems can use this ability to strategically initiate system completions of user utterances. More broadly, this framework facilitates the implementation of a range of overlap behaviors that are common in human dialogue, but have been largely absent in dialogue systems.},
author = {DeVault, David and Sagae, Kenji and Traum, David},
booktitle = {Annual Meeting of the Special Interest Group on Discourse and Dialogue (SIGDIAL)},
doi = {10.1.1.159.5287},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/DeVault, Sagae, Traum - 2009 - Can I Finish Learning When to Respond to Incremental Interpretation Results in Interactive Dialogue(2).pdf:pdf},
isbn = {978-1-932432-64-0},
keywords = {dissertation,interaction},
mendeley-tags = {dissertation,interaction},
number = {September},
pages = {11--20},
publisher = {Association for Computational Linguistics},
title = {{Can I Finish?: Learning When to Respond to Incremental Interpretation Results in Interactive Dialogue}},
url = {http://dl.acm.org/citation.cfm?id=1708378},
year = {2009}
}
@inproceedings{beltagy-EtAl:2013:*SEM,
abstract = {We combine logical and distributional rep- resentations of natural language meaning by transforming distributional similarity judg- ments into weighted inference rules using Markov Logic Networks (MLNs). We show that this framework supports both judg- ing sentence similarity and recognizing tex- tual entailment by appropriately adapting the MLN implementation of logical connectives. We also show that distributional phrase simi- larity, used as textual inference rules created on the fly, improves its performance. 1},
address = {Atlanta, Georgia, USA},
author = {Beltagy, Islam and Chau, Cuong and Boleda, Gemma and Garrette, Dan and Erk, Katrin},
booktitle = {Joint Conference on Lexical and Computational Semantics (*SEM)},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Beltagy et al. - 2013 - Montague Meets Markov Deep Semantics with Probabilistic Logical Form(2).pdf:pdf},
keywords = {nlu,semantics},
mendeley-tags = {nlu,semantics},
month = {jun},
pages = {11--21},
publisher = {Association for Computational Linguistics},
title = {{Montague Meets Markov: Deep Semantics with Probabilistic Logical Form}},
url = {http://www.aclweb.org/anthology/S13-1002},
year = {2013}
}
@article{Williams2016,
author = {Williams, Jason D and Park, Menlo},
doi = {10.5087/dad.2016.301},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Williams, Park - 2016 - The Dialog State Tracking Challenge Series A Review(2).pdf:pdf},
journal = {Dialogue {\&} Discourse},
keywords = {conversational sys-,dialog modeling,dialog state tracking,dialogue-management,dm,dm state-tracking,dst,pomdps,spoken dialog systems,spoken language understanding,tems},
mendeley-tags = {dialogue-management,dm,dm state-tracking,dst,pomdps},
number = {3},
pages = {4--33},
title = {{The Dialog State Tracking Challenge Series : A Review}},
volume = {7},
year = {2016}
}
@article{poesio2011incremental,
author = {Poesio, Massimo},
doi = {10.5087/dad.2011.110},
file = {:home/ckennington/.local/share/data/Mendeley Ltd./Mendeley Desktop/Downloaded/Poesio - 2011 - An incremental model of anaphora and reference resolution based on resource situations(2).pdf:pdf},
isbn = {2152-9620},
issn = {2152-9620},
journal = {Dialogue {\&} Discourse},
keywords = {dissertation,nlu,reference,reference resolution},
mendeley-tags = {dissertation,nlu,reference,reference resolution},
number = {1},
pages = {1--52},
title = {{An incremental model of anaphora and reference resolution based on resource situations}},
url = {http://www.elanguage.net/journals/index.php/dad/article/view/373},
volume = {2},
year = {2011}
}
